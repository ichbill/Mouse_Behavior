{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a14477c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from torch.utils.data import DataLoader, random_split, WeightedRandomSampler\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from torch.utils.data import Subset\n",
    "from torch.optim import Adam\n",
    "import torch.nn as nn\n",
    "from dataset import MouseDataset\n",
    "from model import MouseModel, VisionModel, AudioModel, BehaviorModel\n",
    "from tqdm import tqdm\n",
    "import argparse\n",
    "from collections import Counter\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from sklearn.metrics import accuracy_score\n",
    "# import torch.distributed as dist\n",
    "# from torch.nn.parallel import DistributedDataParallel\n",
    "# from torch.utils.data.distributed import DistributedSampler\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a35e099",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # data path\n",
    "    # parser.add_argument('--video_path', default=\"/data/zhaozhenghao/Projects/Mouse_behavior/dataset/Formalin/frame_folder\", type=str, dest='video_path', help='Video path.')\n",
    "    parser.add_argument('--pred_path', default='alphapose-results.json', type=str, dest='pred_path', help='Prediction path.')\n",
    "    parser.add_argument('--label_path', default='Formalin_acute_pain_1.xlsx', type=str, dest='label_path', help='Label path.')\n",
    "    # parser.add_argument('--audio_path', default='/data/zhaozhenghao/Projects/Mouse_behavior/dataset/Formalin/Formalin_Ultrasound_recording.wav', type=str, dest='audio_path', help='Audio path.')\n",
    "\n",
    "    # hyperparameters\n",
    "    parser.add_argument('--learning_rate', type=float, default=0.0001)\n",
    "    parser.add_argument('--num_epochs', type=int, default=10)\n",
    "    parser.add_argument('--batch_size', type=int, default=32)\n",
    "\n",
    "    # parameters\n",
    "    parser.add_argument('--resampling_rate', type=int, default=1500, help='Resampling rate for audio.')\n",
    "    parser.add_argument('--step', type=int, default=10, help='Step size for sliding window.')\n",
    "    parser.add_argument('--stride', type=int, default=10, help='Stride size for sliding window.')\n",
    "\n",
    "    # tensorboard\n",
    "    parser.add_argument('--tensorboard', type=bool, default=True)\n",
    "    parser.add_argument('--log_dir', type=str, default='./logs')\n",
    "\n",
    "    # ddp\n",
    "    # parser.add_argument(\"--local_rank\", type=int, default=0)\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    return args\n",
    "\n",
    "def uniform_dist(dataset):\n",
    "    labels = np.array([labels for _, labels in dataset])\n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=0)\n",
    "    labels_str = [f\"{label_tensor[0].item()}{label_tensor[1].item()}\" \n",
    "                  for label_tensor in labels]\n",
    "    # Placeholder for X since we only need to stratify based on the labels\n",
    "    X_dummy = np.zeros(len(labels))\n",
    "\n",
    "    # Use 'labels_str' for stratification\n",
    "    for train_index, test_index in sss.split(X_dummy, labels_str):\n",
    "        train_dataset = Subset(dataset, train_index)\n",
    "        test_dataset = Subset(dataset, test_index)\n",
    "    \n",
    "    return train_dataset, test_dataset\n",
    "\n",
    "def get_flat_labels(dataset):\n",
    "    labels = []\n",
    "    for _, label_tensor in dataset:\n",
    "        labels.append(label_tensor[0].item() * 2 + label_tensor[1].item())  # This maps [0,0]->0, [0,1]->1, [1,0]->2, [1,1]->3\n",
    "    return labels\n",
    "\n",
    "# Calculate sample weights\n",
    "def calculate_weights(dataset):\n",
    "    flat_labels = get_flat_labels(dataset)\n",
    "    class_sample_count = torch.tensor([(torch.tensor(flat_labels) == t).sum() for t in torch.unique(torch.tensor(flat_labels), sorted=True)])\n",
    "    weight = 1. / class_sample_count.float()\n",
    "    sample_weights = torch.tensor([weight[t] for t in flat_labels])\n",
    "    print(sample_weights)\n",
    "    return sample_weights\n",
    "\n",
    "def main():\n",
    "    # local_rank = args.local_rank\n",
    "    # dist.init_process_group(backend=\"nccl\", init_method=\"env://\")\n",
    "    local_rank = 0\n",
    "    # torch.cuda.set_device(local_rank)\n",
    "    # device = torch.device('cuda', local_rank)\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "#     if args.tensorboard and local_rank == 0:\n",
    "#         writer = SummaryWriter(args.log_dir)\n",
    "\n",
    "    # dataset\n",
    "    dataset = MouseDataset('alphapose-results.json', 'Formalin_acute_pain_1.xlsx')\n",
    "\n",
    "    #Maintaining the distribution in train and test set\n",
    "    train_dataset, test_dataset = uniform_dist(dataset)\n",
    "    \n",
    "    #\n",
    "    train_weights = calculate_weights(train_dataset)\n",
    "    train_sampler = WeightedRandomSampler(train_weights, len(train_weights))\n",
    "\n",
    "    # Calculate weights for the testing dataset\n",
    "    test_weights = calculate_weights(test_dataset)\n",
    "    test_sampler = WeightedRandomSampler(test_weights, len(test_weights))\n",
    "\n",
    "    # Now, use the samplers in your DataLoader\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, sampler=train_sampler)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32, sampler=test_sampler)\n",
    "    # train_loader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=False, sampler=train_sampler, num_workers=0)\n",
    "    # test_loader = DataLoader(test_dataset, batch_size=args.batch_size, shuffle=False, sampler=test_sampler, num_workers=0)\n",
    "    for steps, (behavior_feat, labels) in enumerate(tqdm(train_loader)):\n",
    "        print(\"behavior_feat : \", behavior_feat)\n",
    "        print(\"behavior_feat_size :\",behavior_feat.shape)\n",
    "        print(\"behavior_feat[0] : \", behavior_feat[0])\n",
    "        print(\"behavior_feat[0].size :\",behavior_feat[0].shape)\n",
    "        print(\"labels : \",labels)\n",
    "        print(\"labels_size :\",labels.shape)\n",
    "        break\n",
    "    return behavior_feat, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b788004e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108211\n",
      "pose_keypoints shape: (108211, 12)\n",
      "pose_keypoints sliding window shape: (10821, 10, 12)\n",
      "label_data shape: 108211\n",
      "label_data sliding window shape: (10821, 2)\n",
      "one_hot_labels shape: 10821\n",
      "behavior_feat shape: 10821\n",
      "valid_indices shape: 10821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_17656\\3768991408.py:32: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  labels = np.array([labels for _, labels in dataset])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (10821,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m main()\n",
      "Cell \u001b[1;32mIn[15], line 76\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     73\u001b[0m dataset \u001b[38;5;241m=\u001b[39m MouseDataset(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124malphapose-results.json\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFormalin_acute_pain_1.xlsx\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     75\u001b[0m \u001b[38;5;66;03m#Maintaining the distribution in train and test set\u001b[39;00m\n\u001b[1;32m---> 76\u001b[0m train_dataset, test_dataset \u001b[38;5;241m=\u001b[39m uniform_dist(dataset)\n\u001b[0;32m     78\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m     79\u001b[0m train_weights \u001b[38;5;241m=\u001b[39m calculate_weights(train_dataset)\n",
      "Cell \u001b[1;32mIn[15], line 32\u001b[0m, in \u001b[0;36muniform_dist\u001b[1;34m(dataset)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21muniform_dist\u001b[39m(dataset):\n\u001b[1;32m---> 32\u001b[0m     labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([labels \u001b[38;5;28;01mfor\u001b[39;00m _, labels \u001b[38;5;129;01min\u001b[39;00m dataset])\n\u001b[0;32m     33\u001b[0m     sss \u001b[38;5;241m=\u001b[39m StratifiedShuffleSplit(n_splits\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     34\u001b[0m     labels_str \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabel_tensor[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mlabel_tensor[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \n\u001b[0;32m     35\u001b[0m                   \u001b[38;5;28;01mfor\u001b[39;00m label_tensor \u001b[38;5;129;01min\u001b[39;00m labels]\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (10821,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f98e6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
